---
title: Redesign BYO Nodes Scenario 
authors:
  - "Jonathan Tong"
reviewers:
  - "Jonathan Tong"
creation-date: `2025-08-20`
last-updated: `2025-08-20`
status: provisional
---

# Title

Redesign BYO Nodes Scenario and Deprecate `preferredNodes` field

## Glossary

- BYO nodes: bring-your-own nodes
- NAP: node auto-provisioning

## Summary

This proposal aims to redesign the bring-your-own (BYO) use case and deprecate the preferred nodes list from `.resource.preferredNodes`. The existing BYO scenario is handled by the preferred nodes list, and instead BYO nodes will only need to match the Workspace label selector. Additionally, the NAP (node auto-provisioning) feature flag will be removed, and NAP will be enabled per Workspace when `resource.instanceType` is set and disabled when `instanceType` is empty.

## Motivation

The initial BYO nodes scenario was implemented with the preferred nodes list, where users would specify the names of the nodes they want to use in the Workspace spec. This approach had several issues that pertain to the design, not just the code, so rather than attempting to introduce awkward fixes one at a time, we will redesign the BYO nodes scenario to simplify the user experience and improve the overall system architecture. The existing limitations are as follows:

1. In order for any node to be selected by the Workspace, it must be labeled to match the Workspace label selector. This is the case for BYO and NAP nodes, so there already is an affiliation between BYO nodes and the Workspace, which means that providing the names of the nodes in the preferred nodes list is redundant. This has been mentioned several times in issues like [this](https://github.com/kaito-project/kaito/pull/1337#pullrequestreview-3122605167).
2. When NAP is enabled and the user has also provided nodes in the preferred nodes list, the name of the field implies that these will be scheduled first. The existing code to [select the nodes](https://github.com/kaito-project/kaito/blob/8c8585a138c4a9273de6149e184ff5b951cd4c18/pkg/utils/common.go#L243-L288) sorts them in order of priority with preferred nodes first, but there isn't a way to guarantee that the scheduler actually picks the nodes from the list out of all possible nodes. For example, if one node is needed and there's an existing NAP node with a preferred node that got added, the scheduler could pick either one. There's no clear way to have the scheduler prioritize nodes in this way, and so dropping the idea of preferred nodes in favor of all qualified nodes sharing the same label would be more clear to the user.
3. The instance type doesn't need to be set by the user when using BYO nodes, but it's defaulted to `Standard_NC24ads_A100_v4` and the GPU size/memory validation is run on that. If an H100 node is provided, for example, to run a very large model, the validation will fail when the model can be run since it's using the wrong SKU.

## Goals

1. Simplify the BYO nodes scenario by removing the preferred nodes list and relying solely on the Workspace label selector for node selection.
2. Clearly define the behavior of how user provided nodes will be handled when NAP is enabled and disabled.
3. Surface errors to the user when there is an error with their provided nodes and cannot run the workload.


## Solution Design

The new design for the BYO scenario is for the user to label them with the corresponding Workspace label selector. NAP (node auto-provisioning) will be enabled or disabled per Workspace based on whether the `instanceType` field is set, eliminating the need for a global NAP feature flag. The `instanceType` field will no longer be defaulted to `Standard_NC24ads_A100_v4` SKU. The behavior is as follows:

### NAP Disabled:

When `.resource.instanceType` is empty or not provided, NAP is disabled for that Workspace. All nodes matching the label selector will be selected and if the amount of nodes is less than the desired amount in the Workspace spec, an error will be returned immediately. The amount is indicated by `.inference.replicas` or the deprecated `.resource.count`. The webhook will then verify that each node is ready/running. If the total amount of ready nodes is less than the desired number of replicas, then an error will be returned again. The Workspace will schedule the model to run on these nodes, and if the amount of nodes exceeds the desired number of replicas, any of the nodes can be selected by the scheduler.

### NAP Enabled:

When `.resource.instanceType` is provided, NAP is enabled for that Workspace. Like the previous scenario, all the BYO nodes will be selected and verified. The user nodes must be of the same instance type or the webhook will return an error. KAITO uses the value of the label `node.kubernetes.io/instance-type` to determine the instance type, so the user provided nodes must also have this label as well. If the amount of ready nodes of the correct instance is less than the count, the auto-provisioner will create new nodes. The scheduler will not distinguish between user provided and auto provisioned nodes.

## Implementation Strategy

The implementation will be split into a few key steps:

### Step 1:

Deprecate the preferred nodes field and remove the default value of `Standard_NC24ads_A100_v4` for `instanceType`. Since the instance type is still used to calculate the GPU memory requirements for validation, we will instead temporarily make the instance type a required field and give an error when it is not provided.

### Step 2:

Merge and implement a separate proposal for calculating GPU memory requirements without needing an instance type. This is covered by an [issue](https://github.com/kaito-project/kaito/issues/1222) to support generic resource scheduling as currently, the validation only works for specific instance types that are documented in the codebase.

### Step 3:

Once the generic method of workload scheduling is defined and implemented, we can revisit the BYO nodes proposal and make the instance type truly optional. This will allow users to provide any node type without being constrained by the default instance type.

# History

- [x] 2025/08/20: Open proposal PR.
- [ ] MM/DD/YYYY: Start model integration.
- [ ] MM/DD/YYYY: Complete model support.
