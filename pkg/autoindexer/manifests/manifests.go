// Copyright (c) KAITO authors.
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package manifests

import (
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"

	batchv1 "k8s.io/api/batch/v1"
	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/resource"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/utils/ptr"

	kaitov1alpha1 "github.com/kaito-project/kaito/api/v1alpha1"
)

const (
	// AutoIndexerImage is the default image for the autoindexer job
	AutoIndexerImage = "mcr.microsoft.com/oss/kaito/autoindexer:latest"

	// Environment variable names used in the indexing container
	EnvIndexName         = "INDEX_NAME"
	EnvRAGEngineEndpoint = "RAGENGINE_ENDPOINT"
	EnvDataSourceType    = "DATASOURCE_TYPE"
	EnvDataSourceConfig  = "DATASOURCE_CONFIG"
	EnvCredentialsConfig = "CREDENTIALS_CONFIG"
	EnvRetryPolicy       = "RETRY_POLICY"

	// Labels used for job identification and management
	LabelAutoIndexerName      = "autoindexer.kaito.io/name"
	LabelAutoIndexerNamespace = "autoindexer.kaito.io/namespace"
	LabelJobType              = "autoindexer.kaito.io/job-type"
	LabelDataSourceType       = "autoindexer.kaito.io/datasource-type"

	// Job type values
	JobTypeOneTime   = "one-time"
	JobTypeScheduled = "scheduled"

	// Default resource limits and requests
	DefaultCPURequest    = "100m"
	DefaultMemoryRequest = "256Mi"
	DefaultCPULimit      = "1"
	DefaultMemoryLimit   = "1Gi"
)

// JobConfig contains the configuration for creating indexing jobs
type JobConfig struct {
	AutoIndexer     *kaitov1alpha1.AutoIndexer
	JobName         string
	JobType         string
	Image           string
	ResourceLimits  *corev1.ResourceRequirements
	ImagePullPolicy corev1.PullPolicy
}

// GenerateIndexingJobManifest creates a Job manifest for document indexing
func GenerateIndexingJobManifest(config JobConfig) *batchv1.Job {
	labels := getJobLabels(config.AutoIndexer, config.JobType)

	job := &batchv1.Job{
		ObjectMeta: metav1.ObjectMeta{
			Name:      config.JobName,
			Namespace: config.AutoIndexer.Namespace,
			Labels:    labels,
			Annotations: map[string]string{
				"autoindexer.kaito.io/spec-hash": generateSpecHash(config.AutoIndexer.Spec),
			},
			OwnerReferences: []metav1.OwnerReference{
				*metav1.NewControllerRef(config.AutoIndexer, kaitov1alpha1.GroupVersion.WithKind("AutoIndexer")),
			},
		},
		Spec: batchv1.JobSpec{
			BackoffLimit: getBackoffLimit(config.AutoIndexer.Spec.RetryPolicy),
			Template: corev1.PodTemplateSpec{
				ObjectMeta: metav1.ObjectMeta{
					Labels: labels,
				},
				Spec: corev1.PodSpec{
					RestartPolicy: corev1.RestartPolicyOnFailure,
					Containers: []corev1.Container{
						generateIndexingContainer(config),
					},
				},
			},
		},
	}

	// Add volumes and volume mounts if credentials are provided
	if config.AutoIndexer.Spec.Credentials != nil {
		addCredentialsMounts(job, config.AutoIndexer.Spec.Credentials)
	}

	return job
}

// GenerateIndexingCronJobManifest creates a CronJob manifest for scheduled document indexing
func GenerateIndexingCronJobManifest(config JobConfig) *batchv1.CronJob {
	if config.AutoIndexer.Spec.Schedule == nil {
		return nil
	}

	labels := getJobLabels(config.AutoIndexer, JobTypeScheduled)
	jobTemplate := GenerateIndexingJobManifest(JobConfig{
		AutoIndexer:     config.AutoIndexer,
		JobName:         "", // Will be generated by CronJob
		JobType:         JobTypeScheduled,
		Image:           config.Image,
		ResourceLimits:  config.ResourceLimits,
		ImagePullPolicy: config.ImagePullPolicy,
	})

	cronJob := &batchv1.CronJob{
		ObjectMeta: metav1.ObjectMeta{
			Name:      config.JobName,
			Namespace: config.AutoIndexer.Namespace,
			Labels:    labels,
			Annotations: map[string]string{
				"autoindexer.kaito.io/spec-hash": generateSpecHash(config.AutoIndexer.Spec),
			},
			OwnerReferences: []metav1.OwnerReference{
				*metav1.NewControllerRef(config.AutoIndexer, kaitov1alpha1.GroupVersion.WithKind("AutoIndexer")),
			},
		},
		Spec: batchv1.CronJobSpec{
			Schedule:          *config.AutoIndexer.Spec.Schedule,
			ConcurrencyPolicy: batchv1.ForbidConcurrent,
			Suspend:           config.AutoIndexer.Spec.Suspend,
			JobTemplate: batchv1.JobTemplateSpec{
				ObjectMeta: jobTemplate.ObjectMeta,
				Spec:       jobTemplate.Spec,
			},
			SuccessfulJobsHistoryLimit: ptr.To[int32](3),
			FailedJobsHistoryLimit:     ptr.To[int32](1),
		},
	}

	return cronJob
}

// generateIndexingContainer creates the main indexing container
func generateIndexingContainer(config JobConfig) corev1.Container {
	image := config.Image
	if image == "" {
		image = AutoIndexerImage
	}

	resourceRequirements := getResourceRequirements(config.ResourceLimits)

	container := corev1.Container{
		Name:            "autoindexer",
		Image:           image,
		ImagePullPolicy: config.ImagePullPolicy,
		Resources:       resourceRequirements,
		Env:             generateEnvironmentVariables(config.AutoIndexer),
		Command:         []string{"python"},
		Args:            []string{"main.py", "--mode=index"},
	}

	return container
}

// generateEnvironmentVariables creates environment variables for the indexing container
func generateEnvironmentVariables(autoIndexer *kaitov1alpha1.AutoIndexer) []corev1.EnvVar {
	envVars := []corev1.EnvVar{
		{
			Name:  EnvIndexName,
			Value: autoIndexer.Spec.IndexName,
		},
		{
			Name:  EnvRAGEngineEndpoint,
			Value: generateRAGEngineEndpoint(autoIndexer),
		},
		{
			Name:  EnvDataSourceType,
			Value: string(autoIndexer.Spec.DataSource.Type),
		},
	}

	// Add data source configuration
	dataSourceConfig, err := generateDataSourceConfig(autoIndexer.Spec.DataSource)
	if err == nil && dataSourceConfig != "" {
		envVars = append(envVars, corev1.EnvVar{
			Name:  EnvDataSourceConfig,
			Value: dataSourceConfig,
		})
	}

	// Add credentials configuration if present
	if autoIndexer.Spec.Credentials != nil {
		credentialsConfig, err := generateCredentialsConfig(autoIndexer.Spec.Credentials)
		if err == nil && credentialsConfig != "" {
			envVars = append(envVars, corev1.EnvVar{
				Name:  EnvCredentialsConfig,
				Value: credentialsConfig,
			})
		}
	}

	// Add retry policy configuration if present
	if autoIndexer.Spec.RetryPolicy != nil {
		retryConfig, err := generateRetryPolicyConfig(autoIndexer.Spec.RetryPolicy)
		if err == nil && retryConfig != "" {
			envVars = append(envVars, corev1.EnvVar{
				Name:  EnvRetryPolicy,
				Value: retryConfig,
			})
		}
	}

	return envVars
}

// generateRAGEngineEndpoint creates the RAGEngine service endpoint URL
func generateRAGEngineEndpoint(autoIndexer *kaitov1alpha1.AutoIndexer) string {
	ragEngineRef := autoIndexer.Spec.RAGEngineRef
	namespace := ragEngineRef.Namespace
	if namespace == "" {
		namespace = autoIndexer.Namespace
	}

	// Assume RAGEngine service follows the naming convention: <ragengine-name>.<namespace>.svc.cluster.local:80
	return fmt.Sprintf("http://%s.%s.svc.cluster.local:80", ragEngineRef.Name, namespace)
}

// generateDataSourceConfig serializes the data source configuration to JSON
func generateDataSourceConfig(dataSource kaitov1alpha1.DataSourceSpec) (string, error) {
	config := map[string]interface{}{
		"type": string(dataSource.Type),
	}

	switch dataSource.Type {
	case kaitov1alpha1.DataSourceTypeGitHub:
		if dataSource.Git != nil {
			config["git"] = map[string]interface{}{
				"repository":   dataSource.Git.Repository,
				"branch":       dataSource.Git.Branch,
				"commit":       dataSource.Git.Commit,
				"paths":        dataSource.Git.Paths,
				"excludePaths": dataSource.Git.ExcludePaths,
			}
		}
	case kaitov1alpha1.DataSourceTypeStatic:
		if dataSource.Static != nil {
			config["static"] = map[string]interface{}{
				"endpoints": dataSource.Static.Endpoints,
			}
		}
	}

	configBytes, err := json.Marshal(config)
	if err != nil {
		return "", err
	}

	return string(configBytes), nil
}

// generateCredentialsConfig serializes the credentials configuration to JSON
func generateCredentialsConfig(credentials *kaitov1alpha1.CredentialsSpec) (string, error) {
	config := map[string]interface{}{
		"type": string(credentials.Type),
	}

	if credentials.SecretRef != nil {
		config["secretRef"] = map[string]interface{}{
			"name": credentials.SecretRef.Name,
			"key":  credentials.SecretRef.Key,
		}
	}

	configBytes, err := json.Marshal(config)
	if err != nil {
		return "", err
	}

	return string(configBytes), nil
}

// generateRetryPolicyConfig serializes the retry policy configuration to JSON
func generateRetryPolicyConfig(retryPolicy *kaitov1alpha1.RetryPolicySpec) (string, error) {
	config := map[string]interface{}{
		"maxRetries": retryPolicy.MaxRetries,
		// "backoffStrategy": retryPolicy.BackoffStrategy,
	}

	// if retryPolicy.InitialDelay != nil {
	// 	config["initialDelay"] = retryPolicy.InitialDelay.Duration.String()
	// }

	// if retryPolicy.MaxDelay != nil {
	// 	config["maxDelay"] = retryPolicy.MaxDelay.Duration.String()
	// }

	configBytes, err := json.Marshal(config)
	if err != nil {
		return "", err
	}

	return string(configBytes), nil
}

// getJobLabels returns the standard labels for AutoIndexer jobs
func getJobLabels(autoIndexer *kaitov1alpha1.AutoIndexer, jobType string) map[string]string {
	return map[string]string{
		LabelAutoIndexerName:      autoIndexer.Name,
		LabelAutoIndexerNamespace: autoIndexer.Namespace,
		LabelJobType:              jobType,
		LabelDataSourceType:       string(autoIndexer.Spec.DataSource.Type),
	}
}

// getBackoffLimit returns the backoff limit based on retry policy
func getBackoffLimit(retryPolicy *kaitov1alpha1.RetryPolicySpec) *int32 {
	if retryPolicy != nil && retryPolicy.MaxRetries > 0 {
		return &retryPolicy.MaxRetries
	}
	return ptr.To[int32](3) // Default backoff limit
}

// getResourceRequirements returns resource requirements with defaults
func getResourceRequirements(limits *corev1.ResourceRequirements) corev1.ResourceRequirements {
	if limits != nil {
		return *limits
	}

	return corev1.ResourceRequirements{
		Requests: corev1.ResourceList{
			corev1.ResourceCPU:    resource.MustParse(DefaultCPURequest),
			corev1.ResourceMemory: resource.MustParse(DefaultMemoryRequest),
		},
		Limits: corev1.ResourceList{
			corev1.ResourceCPU:    resource.MustParse(DefaultCPULimit),
			corev1.ResourceMemory: resource.MustParse(DefaultMemoryLimit),
		},
	}
}

// addCredentialsMounts adds volume mounts for credentials
func addCredentialsMounts(job *batchv1.Job, credentials *kaitov1alpha1.CredentialsSpec) {
	if credentials.SecretRef == nil {
		return
	}

	volumeName := "credentials"
	mountPath := "/etc/credentials"

	// Add volume
	job.Spec.Template.Spec.Volumes = append(job.Spec.Template.Spec.Volumes, corev1.Volume{
		Name: volumeName,
		VolumeSource: corev1.VolumeSource{
			Secret: &corev1.SecretVolumeSource{
				SecretName: credentials.SecretRef.Name,
				Items: []corev1.KeyToPath{
					{
						Key:  credentials.SecretRef.Key,
						Path: "credentials",
					},
				},
			},
		},
	})

	// Add volume mount to container
	if len(job.Spec.Template.Spec.Containers) > 0 {
		job.Spec.Template.Spec.Containers[0].VolumeMounts = append(
			job.Spec.Template.Spec.Containers[0].VolumeMounts,
			corev1.VolumeMount{
				Name:      volumeName,
				MountPath: mountPath,
				ReadOnly:  true,
			},
		)

		// Add environment variable pointing to the credential file
		job.Spec.Template.Spec.Containers[0].Env = append(
			job.Spec.Template.Spec.Containers[0].Env,
			corev1.EnvVar{
				Name:  "CREDENTIALS_FILE",
				Value: fmt.Sprintf("%s/credentials", mountPath),
			},
		)
	}
}

// generateSpecHash creates a hash of the AutoIndexer spec for change detection
func generateSpecHash(spec kaitov1alpha1.AutoIndexerSpec) string {
	// Create proper SHA256 hash from the serialized spec
	specBytes, _ := json.Marshal(spec)
	hash := sha256.Sum256(specBytes)
	return hex.EncodeToString(hash[:])[:8]
}

// GenerateJobName creates a unique job name for the AutoIndexer
func GenerateJobName(autoIndexer *kaitov1alpha1.AutoIndexer, jobType string) string {
	prefix := autoIndexer.Name
	if jobType == JobTypeScheduled {
		return fmt.Sprintf("%s-cronjob", prefix)
	}

	// For one-time jobs, add timestamp-based suffix
	timestamp := metav1.Now().Unix()
	return fmt.Sprintf("%s-job-%d", prefix, timestamp)
}

// ValidateJobConfig validates the job configuration
func ValidateJobConfig(config JobConfig) error {
	if config.AutoIndexer == nil {
		return fmt.Errorf("AutoIndexer cannot be nil")
	}

	if config.JobName == "" {
		return fmt.Errorf("JobName cannot be empty")
	}

	if config.JobType != JobTypeOneTime && config.JobType != JobTypeScheduled {
		return fmt.Errorf("invalid JobType: %s", config.JobType)
	}

	// Validate that schedule is present for scheduled jobs
	if config.JobType == JobTypeScheduled && config.AutoIndexer.Spec.Schedule == nil {
		return fmt.Errorf("Schedule must be specified for scheduled jobs")
	}

	return nil
}

// GetDefaultJobConfig returns a default job configuration
func GetDefaultJobConfig(autoIndexer *kaitov1alpha1.AutoIndexer, jobType string) JobConfig {
	return JobConfig{
		AutoIndexer:     autoIndexer,
		JobName:         GenerateJobName(autoIndexer, jobType),
		JobType:         jobType,
		Image:           AutoIndexerImage,
		ImagePullPolicy: corev1.PullIfNotPresent,
		ResourceLimits:  nil, // Will use defaults
	}
}
